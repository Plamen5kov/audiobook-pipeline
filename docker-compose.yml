services:
  n8n:
    image: n8nio/n8n:latest
    ports:
      - "5678:5678"
    volumes:
      - ./n8n-data:/home/node/.n8n
      - ./voices:/voices:ro
      - ./input:/input:ro
      - ./output:/output
      - ./data:/data
      - ./voice-cast.yaml:/voice-cast.yaml:ro
    environment:
      - N8N_SECURE_COOKIE=false
    restart: unless-stopped

  text-analyzer:
    build: ./services/text-analyzer
    ports:
      - "8001:8001"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - MODEL_NAME=llama3.1:70b
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  script-adapter:
    build: ./services/script-adapter
    ports:
      - "8002:8002"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - MODEL_NAME=llama3.1:70b
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  xtts-v2:
    build: ./services/xtts-v2
    ports:
      - "8003:8003"
    volumes:
      - ./voices:/voices:ro
      - ./data/intermediate:/data/intermediate
      - xtts-models:/root/.local/share/tts
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  audio-assembly:
    build: ./services/audio-assembly
    ports:
      - "8005:8005"
    volumes:
      - ./data/intermediate:/data/intermediate:ro
      - ./output:/output
    restart: unless-stopped

volumes:
  xtts-models:
